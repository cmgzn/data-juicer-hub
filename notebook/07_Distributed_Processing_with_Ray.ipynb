{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 7: Distributed Processing with Ray\n",
    "\n",
    "**Data-Juicer User Guide**\n",
    "\n",
    "- Git Commit: `v1.4.5`\n",
    "- Commit Date: 2026-01-16\n",
    "- Repository: https://github.com/datajuicer/data-juicer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "1. [Setup](#setup)\n",
    "2. [Explore Demo Configurations](#explore-demo-configurations)\n",
    "3. [Run Distributed Processing](#run-distributed-processing)\n",
    "   - [Programmatic Execution with Ray](#programmatic-execution-with-ray)\n",
    "4. [Monitor Resources](#monitor-resources)\n",
    "5. [Ray Dashboard](#ray-dashboard)\n",
    "6. [Multi-Node Cluster Setup](#multi-node-cluster-setup)\n",
    "7. [Try Deduplication Demo](#try-deduplication-demo)\n",
    "8. [Performance Tips](#performance-tips)\n",
    "9.  [Cleanup](#cleanup)\n",
    "10. [Further Reading](#further-reading)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup \n",
    "\n",
    "### Clone Data-Juicer Repository\n",
    "\n",
    "First, let's clone the Data-Juicer repository to access the demo configurations and data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone --depth 1 https://github.com/datajuicer/data-juicer.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Data-Juicer with Ray support\n",
    "!uv pip install py-data-juicer[distributed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd data-juicer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Ray Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To start a local Ray cluster, run this command in your terminal:\n",
    "# !ray start --head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Ray cluster status\n",
    "!ray status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Demo Configurations\n",
    "\n",
    "Data-Juicer provides ready-to-use demo configurations in `demos/process_on_ray/`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available demo configs\n",
    "!ls -lh demos/process_on_ray/configs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the demo configuration\n",
    "!cat demos/process_on_ray/configs/demo.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Distributed Processing\n",
    "\n",
    "Now let's run the distributed processing using the demo configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process with Ray using demo config\n",
    "!dj-process --config demos/process_on_ray/configs/demo.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View sample processed data\n",
    "import os\n",
    "import json\n",
    "\n",
    "output_dir = 'outputs/demo/demo-processed'\n",
    "try:\n",
    "    sample_files = os.listdir(output_dir)\n",
    "    print(f\"Sample files count: {len(sample_files)}\")\n",
    "    for sample_file in sample_files:\n",
    "        with open(os.path.join(output_dir, sample_file), 'r') as f:\n",
    "            print(f\"Sample file: {sample_file}\")\n",
    "            print(json.dumps(json.load(f), indent=4))\n",
    "except FileNotFoundError:\n",
    "    print(\"Output directory not found\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Programmatic Execution with Ray\n",
    "\n",
    "Alternatively, you can run the Ray pipeline programmatically in Python. This approach loads the YAML config as a Python dict and uses Data-Juicer's low-level APIs for maximum flexibility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import ray\n",
    "from data_juicer.ops import load_ops\n",
    "from data_juicer.core.data.dataset_builder import DatasetBuilder\n",
    "from data_juicer.core.ray_exporter import RayExporter\n",
    "from jsonargparse import Namespace\n",
    "\n",
    "# Step 1: Load YAML config as Python dict\n",
    "with open('demos/process_on_ray/configs/demo.yaml', 'r') as f:\n",
    "    config_dict = yaml.safe_load(f)\n",
    "\n",
    "print(\"Loaded config:\")\n",
    "print(f\"  Project: {config_dict.get('project_name')}\")\n",
    "print(f\"  Dataset path: {config_dict.get('dataset_path')}\")\n",
    "print(f\"  Export path: {config_dict.get('export_path')}\")\n",
    "print(f\"  Executor type: {config_dict.get('executor_type')}\")\n",
    "print(f\"  Process operators: {len(config_dict.get('process', []))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Initialize Ray cluster\n",
    "ray.init(ignore_reinit_error=True)\n",
    "print(f\"Ray initialized: {ray.is_initialized()}\")\n",
    "\n",
    "# Step 3: Load dataset as Ray Dataset\n",
    "# Extract dataset_path from config dict\n",
    "ds_cfg = Namespace({\"dataset_path\": config_dict[\"dataset_path\"]})\n",
    "dataset_builder = DatasetBuilder(ds_cfg, executor_type=config_dict.get(\"executor_type\"))\n",
    "\n",
    "ds = dataset_builder.load_dataset()\n",
    "print(f\"Loaded dataset with {ds.data.count()} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Extract process list from config dict and load operators\n",
    "process_list = config_dict[\"process\"]\n",
    "print(f\"Process list: {process_list}\")\n",
    "\n",
    "ops = load_ops(process_list)\n",
    "print(f\"Loaded {len(ops)} operators: {[op._name for op in ops]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Process dataset through operators using RayDataset.process()\n",
    "ds.process(ops)\n",
    "print(f\"Processing complete. Remaining samples: {ds.data.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "print(\"Processed data:\")\n",
    "for i, sample in enumerate(ds.data.take(5), 1):\n",
    "    print(f\"{i}. {sample}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Export results using RayExporter\n",
    "# Extract export settings from config dict\n",
    "export_path = os.path.abspath('./outputs/ray_programmatic/processed')\n",
    "os.makedirs(export_path, exist_ok=True)\n",
    "\n",
    "exporter = RayExporter(\n",
    "    export_path=export_path,\n",
    "    export_type=\"jsonl\"\n",
    ")\n",
    "exporter.export(ds.data, columns=ds.data.columns())\n",
    "print(f\"Export complete to: {export_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    sample_files = os.listdir(export_path)\n",
    "    print(f\"Sample files count: {len(sample_files)}\")\n",
    "    for sample_file in sample_files:\n",
    "        with open(os.path.join(export_path, sample_file), 'r') as f:\n",
    "            print(f\"Sample file: {sample_file}\")\n",
    "            print(json.dumps(json.load(f), indent=4))\n",
    "except FileNotFoundError:\n",
    "    print(\"Output directory not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both execution methods produce the same filtered dataset:\n",
    "- **Command-line with YAML**: Simple and quick for one-off processing with config files\n",
    "- **Programmatic with Python**: Load YAML as dict and use Python API - ideal for:\n",
    "  - Integration into larger Python workflows\n",
    "  - Fine-grained control over each processing step\n",
    "  - Dynamic operator configuration at runtime\n",
    "  - Debugging and step-by-step inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitor Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check resource usage\n",
    "import ray\n",
    "from data_juicer.utils.ray_utils import ray_cpu_count, ray_gpu_count\n",
    "\n",
    "ray.init(ignore_reinit_error=True)\n",
    "\n",
    "print(f\"Total CPUs: {ray_cpu_count()}\")\n",
    "print(f\"Total GPUs: {ray_gpu_count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ray Dashboard\n",
    "\n",
    "Access Ray Dashboard at: `http://localhost:8265`\n",
    "\n",
    "The dashboard provides:\n",
    "- Real-time resource utilization\n",
    "- Task execution timeline\n",
    "- Memory usage statistics\n",
    "- Error logs and debugging info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Node Cluster Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Multi-node Ray cluster setup:\")\n",
    "print(\"\"\"\n",
    "# On head node:\n",
    "ray start --head --port=6379 --num-cpus=8\n",
    "\n",
    "# On worker nodes:\n",
    "ray start --address='<head-node-ip>:6379' --num-cpus=8\n",
    "\n",
    "# In Data-Juicer config:\n",
    "executor_type: 'ray'\n",
    "ray_address: '<head-node-ip>:6379'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Deduplication Demo\n",
    "\n",
    "Data-Juicer also provides a deduplication demo using Ray:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View deduplication config\n",
    "!cat demos/process_on_ray/configs/dedup.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check input directory\n",
    "!ls -lh demos/process_on_ray/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run deduplication\n",
    "!dj-process --config demos/process_on_ray/configs/dedup.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check output directory\n",
    "!ls -lh outputs/demo-dedup/demo-ray-bts-dedup-processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View sample processed data\n",
    "import os\n",
    "import json\n",
    "output_dir = 'outputs/demo-dedup/demo-ray-bts-dedup-processed'\n",
    "try:\n",
    "    sample_files = os.listdir(output_dir)\n",
    "    print(f\"Sample files count: {len(sample_files)}\")\n",
    "    for sample_file in sample_files:\n",
    "        with open(os.path.join(output_dir, sample_file), 'r') as f:\n",
    "            for i, line in enumerate(f):\n",
    "                if i < 3:\n",
    "                    print(json.dumps(json.loads(line), ensure_ascii=False))\n",
    "except FileNotFoundError:\n",
    "    print(\"Output directory not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Tips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance optimization tips for Ray processing:\n",
    "\n",
    "1. **Shard Size**: Adjust export_shard_size based on dataset size\n",
    "   - Smaller shards (100-1000): Better for fault tolerance\n",
    "   - Larger shards (5000-10000): Better for throughput\n",
    "\n",
    "2. **Caching**: Enable caching for repeated operations\n",
    "   use_cache: true\n",
    "   cache_compress: 'gzip'\n",
    "\n",
    "3. **Operator Fusion**: Combine compatible operators\n",
    "   op_fusion: true\n",
    "\n",
    "4. **Resource Allocation**: Match workers to available resources\n",
    "   - CPU-bound ops: More workers\n",
    "   - GPU-bound ops: Fewer workers with GPU allocation\n",
    "\n",
    "5. **Monitoring**: Use Ray Dashboard at http://localhost:8265"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop Ray cluster\n",
    "# !ray stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove cloned Data-Juicer repository\n",
    "!rm -rf data-juicer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Reading\n",
    "\n",
    "- [Distributed Processing Documentation](https://datajuicer.github.io/data-juicer/en/main/docs/Distributed.html)\n",
    "- [Ray Documentation](https://docs.ray.io/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-juicer-hub",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
